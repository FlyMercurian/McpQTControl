"""
è¯­éŸ³èŠå¤©ä¼šè¯æ¨¡å—
ç»§æ‰¿ChatSessionï¼Œé›†æˆè¯­éŸ³å½•åˆ¶å’Œè¯­éŸ³è¯†åˆ«åŠŸèƒ½
"""

import os
import asyncio
import logging
from pathlib import Path
from typing import Optional

from main import ChatSession, LLMClient, MCPClient
from voice_input import VoiceRecorder, KeyboardVoiceInput, AUDIO_AVAILABLE
from speech_recognizer import SpeechRecognizer, VoiceCommandProcessor, VOICE_API_AVAILABLE

logger = logging.getLogger(__name__)


class VoiceChatSession(ChatSession):
    """
    å‡½æ•°åç§°ï¼šVoiceChatSession
    åŠŸèƒ½æè¿°ï¼šè¯­éŸ³èŠå¤©ä¼šè¯ï¼Œæ”¯æŒè¯­éŸ³è¾“å…¥å’Œæ–‡å­—è¾“å…¥ä¸¤ç§æ¨¡å¼
    å‚æ•°è¯´æ˜ï¼š
        - llm_clientï¼šLLMClientï¼ŒLLMå®¢æˆ·ç«¯å®ä¾‹
        - mcp_clientï¼šMCPClientï¼ŒMCPå®¢æˆ·ç«¯å®ä¾‹
        - voice_enabledï¼šboolï¼Œæ˜¯å¦å¯ç”¨è¯­éŸ³åŠŸèƒ½ï¼Œé»˜è®¤True
    è¿”å›å€¼ï¼šVoiceChatSessionå®ä¾‹
    """
    
    def __init__(self, llm_client: LLMClient, mcp_client: MCPClient, voice_enabled: bool = True):
        super().__init__(llm_client, mcp_client)
        
        self.voice_enabled = voice_enabled and AUDIO_AVAILABLE and VOICE_API_AVAILABLE
        self.voice_recorder = None
        self.voice_input = None
        self.speech_recognizer = None
        self.voice_processor = None
        
        # åˆå§‹åŒ–è¯­éŸ³ç»„ä»¶
        if self.voice_enabled:
            try:
                self._initialize_voice_components()
                logger.info("è¯­éŸ³åŠŸèƒ½å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"è¯­éŸ³åŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
                self.voice_enabled = False
        else:
            logger.info("è¯­éŸ³åŠŸèƒ½å·²ç¦ç”¨")
    
    def _initialize_voice_components(self):
        """
        å‡½æ•°åç§°ï¼š_initialize_voice_components
        åŠŸèƒ½æè¿°ï¼šåˆå§‹åŒ–è¯­éŸ³ç›¸å…³ç»„ä»¶
        å‚æ•°è¯´æ˜ï¼šæ— 
        è¿”å›å€¼ï¼šæ— 
        """
        # ä»ç¯å¢ƒå˜é‡è·å–è¯­éŸ³é…ç½®
        sample_rate = int(os.getenv('VOICE_SAMPLE_RATE', '16000'))
        max_duration = int(os.getenv('MAX_RECORDING_DURATION', '30'))
        
        # åˆå§‹åŒ–å½•éŸ³å™¨
        self.voice_recorder = VoiceRecorder(
            sample_rate=sample_rate,
            max_duration=max_duration
        )
        
        # åˆå§‹åŒ–é”®ç›˜è¾“å…¥ç›‘å¬å™¨
        self.voice_input = KeyboardVoiceInput(self.voice_recorder)
        
        # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
        voice_model = os.getenv('VOICE_MODEL', 'qwen-omni-turbo-0119')
        self.speech_recognizer = SpeechRecognizer(model_name=voice_model)
        
        # åˆå§‹åŒ–è¯­éŸ³æŒ‡ä»¤å¤„ç†å™¨
        self.voice_processor = VoiceCommandProcessor(self.speech_recognizer)
    
    async def cleanup(self) -> None:
        """
        å‡½æ•°åç§°ï¼šcleanup
        åŠŸèƒ½æè¿°ï¼šæ¸…ç†è¯­éŸ³èµ„æºå’ŒMCPå®¢æˆ·ç«¯èµ„æº
        å‚æ•°è¯´æ˜ï¼šæ— 
        è¿”å›å€¼ï¼šæ— 
        """
        try:
            # æ¸…ç†è¯­éŸ³èµ„æº
            if self.voice_recorder:
                self.voice_recorder.cleanup()
                
            # æ¸…ç†MCPèµ„æº
            await super().cleanup()
            
        except Exception as e:
            logger.warning(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")
    
    def _get_user_input(self, prompt: str = "ç”¨æˆ·") -> str:
        """
        å‡½æ•°åç§°ï¼š_get_user_input
        åŠŸèƒ½æè¿°ï¼šè·å–ç”¨æˆ·è¾“å…¥ï¼Œæ”¯æŒè¯­éŸ³å’Œæ–‡å­—ä¸¤ç§æ¨¡å¼
        å‚æ•°è¯´æ˜ï¼š
            - promptï¼šè¾“å…¥æç¤ºç¬¦
        è¿”å›å€¼ï¼šstrï¼Œç”¨æˆ·è¾“å…¥å†…å®¹
        """
        if self.voice_enabled:
            # è¯­éŸ³+æ–‡å­—æ··åˆæ¨¡å¼
            print(f"\n{prompt}> ", end="")
            print("ğŸ’¬ è¾“å…¥æ–¹å¼ï¼šç›´æ¥è¾“å…¥æ–‡å­— æˆ– æŒ‰ [Vé”®] è¯­éŸ³è¾“å…¥ï¼ˆæŒ‰ä¸€æ¬¡å¼€å§‹ï¼Œå†æŒ‰ä¸€æ¬¡ç»“æŸï¼‰")
            
            # å°è¯•è¯­éŸ³è¾“å…¥
            audio_file = self.voice_input.wait_for_voice_input()
            
            if audio_file:
                # æœ‰è¯­éŸ³è¾“å…¥ï¼Œè¿›è¡Œè¯†åˆ«
                return self._process_voice_input(audio_file)
            else:
                # æ²¡æœ‰è¯­éŸ³è¾“å…¥ï¼Œç­‰å¾…æ–‡å­—è¾“å…¥
                return input(f"{prompt}> ").strip()
        else:
            # çº¯æ–‡å­—æ¨¡å¼
            return input(f"{prompt}> ").strip()
    
    def _process_voice_input(self, audio_file_path: str) -> str:
        """
        å‡½æ•°åç§°ï¼š_process_voice_input
        åŠŸèƒ½æè¿°ï¼šå¤„ç†è¯­éŸ³è¾“å…¥ï¼Œè½¬æ¢ä¸ºæ–‡å­—
        å‚æ•°è¯´æ˜ï¼š
            - audio_file_pathï¼šå½•éŸ³æ–‡ä»¶è·¯å¾„
        è¿”å›å€¼ï¼šstrï¼Œè¯†åˆ«çš„æ–‡å­—å†…å®¹
        """
        try:
            print("ğŸ”„ è¯­éŸ³è¯†åˆ«ä¸­ï¼Œè¯·ç¨å€™...")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºé™éŸ³ï¼ˆç®€å•æ£€æŸ¥ï¼Œä¸è°ƒç”¨APIï¼‰
            if self.speech_recognizer.is_silent_audio(audio_file_path):
                print("âš ï¸ æ£€æµ‹åˆ°é™éŸ³æ–‡ä»¶ï¼Œå·²å¿½ç•¥")
                return ""
            
            # è¯­éŸ³è¯†åˆ« - ä½¿ç”¨ä¼˜åŒ–çš„æç¤ºè¯
            recognized_text = self.speech_recognizer.recognize_from_file(
                audio_file_path, 
                "å°†éŸ³é¢‘è½¬ä¸ºç®€çŸ­æ–‡å­—æŒ‡ä»¤ï¼Œä¸è¦è§£é‡Šä»£ç ï¼Œåªè¦ç”¨æˆ·è¯´çš„è¯"
            )
            
            # æ£€æŸ¥è¯†åˆ«ç»“æœæ˜¯å¦ä¸ºç©ºæˆ–å¤ªçŸ­
            if not recognized_text or len(recognized_text.strip()) < 2:
                print("âš ï¸ è¯­éŸ³è¯†åˆ«ç»“æœä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œå·²å¿½ç•¥")
                return ""
            
            print(f"ğŸ“ è¯†åˆ«ç»“æœ: {recognized_text}")
            
            # ç¡®è®¤æˆ–é‡å½•
            if self._should_auto_confirm():
                return recognized_text
            else:
                return self._confirm_voice_input(recognized_text, audio_file_path)
                
        except Exception as e:
            error_msg = f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            logger.error(error_msg)
            return ""
    
    def _should_auto_confirm(self) -> bool:
        """
        å‡½æ•°åç§°ï¼š_should_auto_confirm
        åŠŸèƒ½æè¿°ï¼šæ£€æŸ¥æ˜¯å¦åº”è¯¥è‡ªåŠ¨ç¡®è®¤è¯­éŸ³è¯†åˆ«ç»“æœ
        å‚æ•°è¯´æ˜ï¼šæ— 
        è¿”å›å€¼ï¼šboolï¼Œæ˜¯å¦è‡ªåŠ¨ç¡®è®¤
        """
        return os.getenv('AUTO_CONFIRM_VOICE', 'false').lower() == 'true'
    
    def _confirm_voice_input(self, recognized_text: str, audio_file_path: str) -> str:
        """
        å‡½æ•°åç§°ï¼š_confirm_voice_input
        åŠŸèƒ½æè¿°ï¼šç¡®è®¤è¯­éŸ³è¯†åˆ«ç»“æœï¼Œæ”¯æŒé‡å½•å’Œæ‰‹åŠ¨è¾“å…¥
        å‚æ•°è¯´æ˜ï¼š
            - recognized_textï¼šè¯†åˆ«çš„æ–‡å­—
            - audio_file_pathï¼šéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        è¿”å›å€¼ï¼šstrï¼Œæœ€ç»ˆç¡®è®¤çš„è¾“å…¥å†…å®¹
        """
        while True:
            choice = input("âœ… ç¡®è®¤æ‰§è¡Œæ­¤æ“ä½œ? (yç¡®è®¤/næ‰‹åŠ¨è¾“å…¥/ré‡å½•/sè·³è¿‡): ").lower().strip()
            
            if choice == 'y' or choice == '':
                return recognized_text
            elif choice == 'n':
                manual_input = input("è¯·æ‰‹åŠ¨è¾“å…¥: ").strip()
                return manual_input
            elif choice == 'r':
                print("ğŸ¤ è¯·é‡æ–°å½•éŸ³...")
                audio_file = self.voice_input.wait_for_voice_input("é‡æ–°å½•éŸ³")
                if audio_file:
                    return self._process_voice_input(audio_file)
                else:
                    print("âš ï¸ é‡å½•å–æ¶ˆ")
                    continue
            elif choice == 's':
                return ""
            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ y/n/r/s")
    
    async def start(self, system_message: str) -> None:
        """
        å‡½æ•°åç§°ï¼šstart
        åŠŸèƒ½æè¿°ï¼šå¯åŠ¨è¯­éŸ³èŠå¤©ä¼šè¯çš„ä¸»å¾ªç¯
        å‚æ•°è¯´æ˜ï¼š
            - system_messageï¼šç³»ç»Ÿæ¶ˆæ¯
        è¿”å›å€¼ï¼šæ— 
        """
        messages = [{"role": "system", "content": system_message}]
        
        # æ‰“å°å¯åŠ¨ä¿¡æ¯
        print("=== QTåº”ç”¨è¯­éŸ³æ§åˆ¶åŠ©æ‰‹å·²å¯åŠ¨ ===")
        print("ğŸ¤ è¯­éŸ³æ¨¡å¼:", "âœ… å·²å¯ç”¨" if self.voice_enabled else "âŒ å·²ç¦ç”¨")
        print("ğŸ’¬ æ”¯æŒçš„è¾“å…¥æ–¹å¼:")
        if self.voice_enabled:
            print("  â€¢ ç›´æ¥è¾“å…¥æ–‡å­—")
            print("  â€¢ æŒ‰ä½ [Vé”®] è¯­éŸ³è¾“å…¥")
        else:
            print("  â€¢ ä»…æ”¯æŒæ–‡å­—è¾“å…¥")
        print("  â€¢ è¾“å…¥ 'quit/exit/é€€å‡º' ç»“æŸä¼šè¯")
        
        print("\nğŸ“ æ”¯æŒçš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤:")
        print("  â€¢ ç™»å½•è´¦å· <ç”¨æˆ·å> <å¯†ç >")
        print("  â€¢ ç‚¹å‡»æµ‹è¯•æŒ‰é’®")
        print("  â€¢ æŸ¥çœ‹åº”ç”¨çŠ¶æ€")
        print("=" * 40)
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥ï¼ˆè¯­éŸ³æˆ–æ–‡å­—ï¼‰
                user_input = self._get_user_input("ç”¨æˆ·")
                
                if user_input.lower() in ["quit", "exit", "é€€å‡º"]:
                    print('QTæ§åˆ¶åŠ©æ‰‹é€€å‡º')
                    break
                    
                if not user_input:
                    continue
                    
                messages.append({"role": "user", "content": user_input})

                # è·å–LLMçš„åˆå§‹å“åº”
                llm_response = self.llm_client.get_response(messages)
                print("åŠ©æ‰‹:", llm_response)

                # å¤„ç†å¯èƒ½çš„å·¥å…·è°ƒç”¨
                result = await self.process_llm_response(llm_response)
                
                # å¦‚æœå¤„ç†ç»“æœä¸åŸå§‹å“åº”ä¸åŒï¼Œè¯´æ˜æ‰§è¡Œäº†å·¥å…·è°ƒç”¨
                if result != llm_response:
                    print(f"ğŸ› ï¸ {result}")  # æ˜¾ç¤ºå·¥å…·æ‰§è¡Œç»“æœ
                    
                    # å°†å·¥å…·æ‰§è¡Œç»“æœå‘é€å›LLMè·å–å‹å¥½å“åº”
                    messages.append({"role": "assistant", "content": llm_response})
                    messages.append({"role": "system", "content": result})
                    
                    # è·å–LLMçš„å‹å¥½å“åº”
                    friendly_response = self.llm_client.get_response(messages)
                    print("åŠ©æ‰‹:", friendly_response)
                    messages.append({"role": "assistant", "content": friendly_response})
                else:
                    # éå·¥å…·è°ƒç”¨ï¼Œç›´æ¥æ·»åŠ åˆ°æ¶ˆæ¯å†å²
                    messages.append({"role": "assistant", "content": llm_response})

            except KeyboardInterrupt:
                print('\nQTæ§åˆ¶åŠ©æ‰‹é€€å‡º')
                break
            except Exception as e:
                logger.error(f"Voice chat session error: {e}")
                print(f"å‘ç”Ÿé”™è¯¯: {e}")
                
                # è¯­éŸ³åŠŸèƒ½å‡ºé”™æ—¶ï¼Œå¯ä»¥é™çº§åˆ°æ–‡å­—æ¨¡å¼
                if self.voice_enabled and "è¯­éŸ³" in str(e):
                    print("âš ï¸ è¯­éŸ³åŠŸèƒ½å¼‚å¸¸ï¼Œå·²åˆ‡æ¢åˆ°æ–‡å­—è¾“å…¥æ¨¡å¼")
                    self.voice_enabled = False


def test_voice_chat():
    """æµ‹è¯•è¯­éŸ³èŠå¤©åŠŸèƒ½"""
    print("ğŸ™ï¸ è¯­éŸ³èŠå¤©æµ‹è¯•")
    print("=" * 40)
    
    try:
        # è¿™é‡Œåªæ˜¯æµ‹è¯•ç»„ä»¶åˆå§‹åŒ–ï¼Œä¸è¿è¡Œå®Œæ•´ä¼šè¯
        from main import LLMClient, MCPClient
        
        # æ¨¡æ‹Ÿå®¢æˆ·ç«¯ï¼ˆæµ‹è¯•ç”¨ï¼‰
        class MockLLMClient:
            def get_response(self, messages):
                return "æµ‹è¯•å“åº”"
        
        class MockMCPClient:
            async def cleanup(self):
                pass
        
        llm_client = MockLLMClient()
        mcp_client = MockMCPClient()
        
        voice_session = VoiceChatSession(llm_client, mcp_client, voice_enabled=True)
        
        if voice_session.voice_enabled:
            print("âœ… è¯­éŸ³èŠå¤©ä¼šè¯åˆå§‹åŒ–æˆåŠŸ")
            print("âœ… è¯­éŸ³ç»„ä»¶å¯ç”¨")
        else:
            print("âš ï¸ è¯­éŸ³åŠŸèƒ½ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ–‡å­—æ¨¡å¼")
            
        # æ¸…ç†èµ„æº
        asyncio.run(voice_session.cleanup())
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    test_voice_chat() 
import asyncio
import json
import logging
import os
from typing import List, Dict, Any
from pathlib import Path
import httpx
from openai import OpenAI
from fastmcp import Client
from dotenv import load_dotenv


# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MCPClient:
    """
    å‡½æ•°åç§°ï¼šMCPClient
    åŠŸèƒ½æè¿°ï¼šMCPå®¢æˆ·ç«¯ï¼Œè´Ÿè´£è¿æ¥MCPæœåŠ¡å™¨å¹¶æ‰§è¡Œå·¥å…·è°ƒç”¨
    å‚æ•°è¯´æ˜ï¼šæ— æ„é€ å‚æ•°
    è¿”å›å€¼ï¼šMCPClientå®ä¾‹
    """
    
    def __init__(self):
        self.client = None
        self.server_url = None
        
    async def connect_to_server(self, server_url: str):
        """
        å‡½æ•°åç§°ï¼šconnect_to_server
        åŠŸèƒ½æè¿°ï¼šè¿æ¥åˆ°FastMCPæœåŠ¡å™¨
        å‚æ•°è¯´æ˜ï¼š
            - server_urlï¼šstrï¼ŒMCPæœåŠ¡å™¨SSEåœ°å€
        è¿”å›å€¼ï¼šæ— 
        """
        self.server_url = server_url
        # ä½¿ç”¨FastMCP Clientè¿æ¥åˆ°SSEæœåŠ¡å™¨
        self.client = Client(server_url + "/sse")
        logger.info(f"Prepared FastMCP client for {server_url}")
        
    async def list_tools(self) -> List[Dict[str, Any]]:
        """
        å‡½æ•°åç§°ï¼šlist_tools
        åŠŸèƒ½æè¿°ï¼šè·å–MCPæœåŠ¡å™¨æä¾›çš„å·¥å…·åˆ—è¡¨
        å‚æ•°è¯´æ˜ï¼šæ— 
        è¿”å›å€¼ï¼šList[Dict]ï¼Œå·¥å…·åˆ—è¡¨
        """
        if not self.client:
            raise Exception("Not connected to MCP server")
            
        try:
            async with self.client as client:
                tools = await client.list_tools()
                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                return [tool.model_dump() for tool in tools]
        except Exception as e:
            logger.error(f"Error listing tools: {e}")
            return []
            
    async def execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -> str:
        """
        å‡½æ•°åç§°ï¼šexecute_tool
        åŠŸèƒ½æè¿°ï¼šæ‰§è¡ŒMCPå·¥å…·
        å‚æ•°è¯´æ˜ï¼š
            - tool_nameï¼šstrï¼Œå·¥å…·åç§°
            - argumentsï¼šDictï¼Œå·¥å…·å‚æ•°
        è¿”å›å€¼ï¼šstrï¼Œæ‰§è¡Œç»“æœ
        """
        if not self.client:
            raise Exception("Not connected to MCP server")
            
        try:
            async with self.client as client:
                result = await client.call_tool(tool_name, arguments)
                if hasattr(result, 'content') and result.content:
                    return result.content[0].text if result.content else 'No result'
                else:
                    return str(result)
        except Exception as e:
            error_msg = f"Error executing tool {tool_name}: {str(e)}"
            logger.error(error_msg)
            return error_msg
            
    async def cleanup(self):
        """
        å‡½æ•°åç§°ï¼šcleanup
        åŠŸèƒ½æè¿°ï¼šæ¸…ç†MCPå®¢æˆ·ç«¯èµ„æº
        å‚æ•°è¯´æ˜ï¼šæ— 
        è¿”å›å€¼ï¼šæ— 
        """
        # FastMCP Clientä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œæ— éœ€æ‰‹åŠ¨æ¸…ç†
        logger.info("MCP client cleanup completed")


class LLMClient:
    """
    å‡½æ•°åç§°ï¼šLLMClient
    åŠŸèƒ½æè¿°ï¼šLLMå®¢æˆ·ç«¯ï¼Œè´Ÿè´£ä¸å¤§è¯­è¨€æ¨¡å‹APIé€šä¿¡
    å‚æ•°è¯´æ˜ï¼š
        - model_nameï¼šstrï¼Œæ¨¡å‹åç§°
        - urlï¼šstrï¼ŒAPIåœ°å€
        - api_keyï¼šstrï¼ŒAPIå¯†é’¥
    è¿”å›å€¼ï¼šLLMClientå®ä¾‹
    """

    def __init__(self, model_name: str, url: str, api_key: str) -> None:
        self.model_name = model_name
        self.url = url
        self.client = OpenAI(api_key=api_key, base_url=url)

    def get_response(self, messages: List[Dict[str, str]]) -> str:
        """
        å‡½æ•°åç§°ï¼šget_response
        åŠŸèƒ½æè¿°ï¼šå‘é€æ¶ˆæ¯ç»™LLMå¹¶è·å–å“åº”
        å‚æ•°è¯´æ˜ï¼š
            - messagesï¼šList[Dict]ï¼Œå¯¹è¯æ¶ˆæ¯åˆ—è¡¨
        è¿”å›å€¼ï¼šstrï¼ŒLLMå“åº”å†…å®¹
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                stream=False
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error getting LLM response: {e}")
            return f"LLMè°ƒç”¨å¤±è´¥: {str(e)}"


class ChatSession:
    """
    å‡½æ•°åç§°ï¼šChatSession
    åŠŸèƒ½æè¿°ï¼šèŠå¤©ä¼šè¯ï¼Œå¤„ç†ç”¨æˆ·è¾“å…¥å’ŒLLMå“åº”ï¼Œå¹¶ä¸MCPå·¥å…·äº¤äº’
    å‚æ•°è¯´æ˜ï¼š
        - llm_clientï¼šLLMClientï¼ŒLLMå®¢æˆ·ç«¯å®ä¾‹
        - mcp_clientï¼šMCPClientï¼ŒMCPå®¢æˆ·ç«¯å®ä¾‹
    è¿”å›å€¼ï¼šChatSessionå®ä¾‹
    """

    def __init__(self, llm_client: LLMClient, mcp_client: MCPClient) -> None:
        self.mcp_client = mcp_client
        self.llm_client = llm_client

    async def cleanup(self) -> None:
        """
        å‡½æ•°åç§°ï¼šcleanup
        åŠŸèƒ½æè¿°ï¼šæ¸…ç†MCPå®¢æˆ·ç«¯èµ„æº
        å‚æ•°è¯´æ˜ï¼šæ— 
        è¿”å›å€¼ï¼šæ— 
        """
        try:
            await self.mcp_client.cleanup()
        except Exception as e:
            logging.warning(f"Warning during final cleanup: {e}")

    async def process_llm_response(self, llm_response: str) -> str:
        """
        å‡½æ•°åç§°ï¼šprocess_llm_response
        åŠŸèƒ½æè¿°ï¼šå¤„ç†LLMå“åº”ï¼Œè§£æå·¥å…·è°ƒç”¨å¹¶æ‰§è¡Œ
        å‚æ•°è¯´æ˜ï¼š
            - llm_responseï¼šstrï¼ŒLLMå“åº”å†…å®¹
        è¿”å›å€¼ï¼šstrï¼Œå¤„ç†åçš„ç»“æœ
        """
        try:
            logger.info(f"ğŸ” å¤„ç†LLMå“åº”: {llm_response[:100]}...")
            
            # æ¸…ç†å“åº”å†…å®¹
            cleaned_response = llm_response.strip()
            
            # ç§»é™¤markdownæ ¼å¼
            if cleaned_response.startswith('```json'):
                cleaned_response = cleaned_response.strip('```json').strip('```').strip()
                logger.info("âœ‚ï¸ å·²ç§»é™¤markdownæ ¼å¼")
            
            # ç§»é™¤å¯èƒ½çš„XMLæ ‡è®°å’Œå¤šä½™å†…å®¹
            if '</tool_call>' in cleaned_response:
                # æå–JSONéƒ¨åˆ†ï¼Œå»æ‰</tool_call>æ ‡è®°
                cleaned_response = cleaned_response.split('</tool_call>')[0].strip()
                logger.info("âœ‚ï¸ å·²ç§»é™¤tool_callæ ‡è®°")
            
            # æŸ¥æ‰¾JSONéƒ¨åˆ† - ä»ç¬¬ä¸€ä¸ª{å¼€å§‹åˆ°æœ€åä¸€ä¸ª}ç»“æŸ
            start_idx = cleaned_response.find('{')
            end_idx = cleaned_response.rfind('}')
            
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                json_part = cleaned_response[start_idx:end_idx+1]
                logger.info(f"âœ‚ï¸ æå–JSONéƒ¨åˆ†: {json_part}")
            else:
                json_part = cleaned_response
            
            tool_call = json.loads(json_part)
            logger.info(f"âœ… JSONè§£ææˆåŠŸ: {tool_call}")
            
            if "tool" in tool_call and "arguments" in tool_call:
                # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
                tools = await self.mcp_client.list_tools()
                tool_names = [tool.get('name') for tool in tools]
                logger.info(f"ğŸ”§ å¯ç”¨å·¥å…·: {tool_names}")
                logger.info(f"ğŸ¯ è¯·æ±‚å·¥å…·: {tool_call['tool']}")
                
                if tool_call["tool"] in tool_names:
                    try:
                        logger.info(f"âš¡ å¼€å§‹æ‰§è¡Œå·¥å…·: {tool_call['tool']} å‚æ•°: {tool_call['arguments']}")
                        
                        # æ‰§è¡Œå·¥å…·è°ƒç”¨
                        result = await self.mcp_client.execute_tool(
                            tool_call["tool"], tool_call["arguments"]
                        )
                        
                        logger.info(f"âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ: {result}")
                        final_result = f"å·¥å…·æ‰§è¡Œç»“æœ: {result}"
                        print(f"ğŸ”§ {final_result}")  # ç«‹å³æ‰“å°ç»“æœ
                        return final_result
                        
                    except Exception as e:
                        error_msg = f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}"
                        logger.error(error_msg)
                        print(f"âŒ {error_msg}")  # ç«‹å³æ‰“å°é”™è¯¯
                        return error_msg
                        
                error_msg = f"æœªæ‰¾åˆ°å·¥å…·: {tool_call['tool']} (å¯ç”¨: {tool_names})"
                logger.warning(error_msg)
                print(f"âš ï¸ {error_msg}")  # ç«‹å³æ‰“å°è­¦å‘Š
                return error_msg
                
            logger.info("ğŸ“ éå·¥å…·è°ƒç”¨ï¼Œè¿”å›åŸå§‹å“åº”")
            return llm_response
        except json.JSONDecodeError as e:
            # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥è¿”å›åŸå§‹å“åº”
            logger.info(f"ğŸ“ éJSONæ ¼å¼å“åº”ï¼Œç›´æ¥è¿”å›: {str(e)}")
            return llm_response

    async def start(self, system_message: str) -> None:
        """
        å‡½æ•°åç§°ï¼šstart
        åŠŸèƒ½æè¿°ï¼šå¯åŠ¨èŠå¤©ä¼šè¯çš„ä¸»å¾ªç¯
        å‚æ•°è¯´æ˜ï¼š
            - system_messageï¼šstrï¼Œç³»ç»Ÿæ¶ˆæ¯
        è¿”å›å€¼ï¼šæ— 
        """
        messages = [{"role": "system", "content": system_message}]
        print("=== QTåº”ç”¨æ§åˆ¶åŠ©æ‰‹å·²å¯åŠ¨ ===")
        print("å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤:")
        print("- ç™»å½•è´¦å· <ç”¨æˆ·å> <å¯†ç >")
        print("- ç‚¹å‡»æµ‹è¯•æŒ‰é’®") 
        print("- æŸ¥çœ‹åº”ç”¨çŠ¶æ€")
        print("- é€€å‡º (è¾“å…¥ quit/exit/é€€å‡º)")
        print("================================")
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("ç”¨æˆ·: ").strip()
                if user_input.lower() in ["quit", "exit", "é€€å‡º"]:
                    print('QTæ§åˆ¶åŠ©æ‰‹é€€å‡º')
                    break
                    
                if not user_input:
                    continue
                    
                messages.append({"role": "user", "content": user_input})

                # è·å–LLMçš„åˆå§‹å“åº”
                llm_response = self.llm_client.get_response(messages)
                print("åŠ©æ‰‹:", llm_response)

                # å¤„ç†å¯èƒ½çš„å·¥å…·è°ƒç”¨
                result = await self.process_llm_response(llm_response)

                # å¦‚æœå¤„ç†ç»“æœä¸åŸå§‹å“åº”ä¸åŒï¼Œè¯´æ˜æ‰§è¡Œäº†å·¥å…·è°ƒç”¨ï¼Œéœ€è¦è¿›ä¸€æ­¥å¤„ç†
                while result != llm_response:
                    messages.append({"role": "assistant", "content": llm_response})
                    messages.append({"role": "system", "content": result})

                    # å°†å·¥å…·æ‰§è¡Œç»“æœå‘é€å›LLMè·å–æ–°å“åº”
                    llm_response = self.llm_client.get_response(messages)
                    result = await self.process_llm_response(llm_response)
                    print("åŠ©æ‰‹:", llm_response)

                messages.append({"role": "assistant", "content": llm_response})

            except KeyboardInterrupt:
                print('\nQTæ§åˆ¶åŠ©æ‰‹é€€å‡º')
                break
            except Exception as e:
                logger.error(f"Chat session error: {e}")
                print(f"å‘ç”Ÿé”™è¯¯: {e}")


def load_env_config():
    """
    å‡½æ•°åç§°ï¼šload_env_config
    åŠŸèƒ½æè¿°ï¼šåŠ è½½ç¯å¢ƒå˜é‡é…ç½®
    å‚æ•°è¯´æ˜ï¼šæ— 
    è¿”å›å€¼ï¼šæ— 
    """
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    current_dir = Path(__file__).parent
    config_file = current_dir / "config.env"
    
    if config_file.exists():
        load_dotenv(config_file)
        logger.info(f"ä» {config_file} åŠ è½½ç¯å¢ƒå˜é‡")
    else:
        logger.warning(f"é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")


async def main():
    """
    å‡½æ•°åç§°ï¼šmain
    åŠŸèƒ½æè¿°ï¼šä¸»å‡½æ•°ï¼Œåˆå§‹åŒ–å®¢æˆ·ç«¯å¹¶å¯åŠ¨èŠå¤©ä¼šè¯
    å‚æ•°è¯´æ˜ï¼šæ— 
    è¿”å›å€¼ï¼šæ— 
    """
    # åŠ è½½ç¯å¢ƒå˜é‡é…ç½®
    load_env_config()
    
    # åˆå§‹åŒ–MCPå®¢æˆ·ç«¯
    mcp_client = MCPClient()
    
    # ä»ç¯å¢ƒå˜é‡è·å–LLMé…ç½®
    model_name = os.getenv('LLM_MODEL_NAME', 'qwen-plus-latest')
    base_url = os.getenv('LLM_BASE_URL', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
    
    # è·å–APIå¯†é’¥ï¼Œæ”¯æŒå¤šä¸ªæä¾›å•†
    api_key = (os.getenv('DASHSCOPE_API_KEY') or 
               os.getenv('OPENAI_API_KEY') or
               os.getenv('ZHIPUAI_API_KEY') or 
               os.getenv('DEEPSEEK_API_KEY'))
    
    if not api_key:
        print("âŒ è¯·åœ¨config.envæ–‡ä»¶ä¸­è®¾ç½®APIå¯†é’¥ (DASHSCOPE_API_KEY, OPENAI_API_KEY, ZHIPUAI_API_KEY æˆ– DEEPSEEK_API_KEY)")
        return
        
    llm_client = LLMClient(
        model_name=model_name,
        api_key=api_key,
        url=base_url
    )
    
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
    logger.info(f"APIåœ°å€: {base_url}")
    
    chat_session = ChatSession(llm_client=llm_client, mcp_client=mcp_client)
    
    try:
        # è¿æ¥åˆ°MCPæœåŠ¡å™¨
        mcp_server_url = os.getenv('MCP_SERVER_URL', 'http://localhost:8000')
        logger.info(f"MCPæœåŠ¡å™¨åœ°å€: {mcp_server_url}")
        await mcp_client.connect_to_server(mcp_server_url)
        
        # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨å¹¶æ ¼å¼åŒ–ä¸ºç³»ç»Ÿæç¤ºçš„ä¸€éƒ¨åˆ†
        tools = await mcp_client.list_tools()
        tools_description = json.dumps(tools, ensure_ascii=False, indent=2)

        # QTåº”ç”¨æ§åˆ¶ä¸“ç”¨ç³»ç»Ÿæç¤ºè¯
        system_message = f'''
        ä½ æ˜¯ä¸€ä¸ªQTåº”ç”¨ç¨‹åºæ§åˆ¶åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·æ“ä½œQTåº”ç”¨ç¨‹åºã€‚

        å¯ç”¨å·¥å…·ï¼š{tools_description}

        å“åº”è§„åˆ™ï¼š
        1ã€å½“ç”¨æˆ·è¯·æ±‚æ‰§è¡ŒQTæ“ä½œæ—¶ï¼Œè¿”å›ä¸¥æ ¼ç¬¦åˆä»¥ä¸‹æ ¼å¼çš„çº¯å‡€JSONï¼š
        {{
            "tool": "tool-name",
            "arguments": {{
                "argument-name": "value"
            }}
        }}

        2ã€ç¦æ­¢åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
         - Markdownæ ‡è®°ï¼ˆå¦‚```jsonï¼‰
         - è‡ªç„¶è¯­è¨€è§£é‡Šå‰ç¼€ï¼ˆå¦‚"ç»“æœï¼š"ï¼‰
         - å¤šä½™çš„æ ¼å¼åŒ–ç¬¦å·

        3ã€å¸¸è§æŒ‡ä»¤æ˜ å°„ï¼š
         - "ç™»å½•" æˆ– "ç™»å½•è´¦å·" â†’ ä½¿ç”¨ login å·¥å…·
         - "ç‚¹å‡»æµ‹è¯•æŒ‰é’®" æˆ– "æµ‹è¯•" â†’ ä½¿ç”¨ test_button å·¥å…·  
         - "æŸ¥çœ‹çŠ¶æ€" æˆ– "è·å–çŠ¶æ€" â†’ ä½¿ç”¨ get_state å·¥å…·

        4ã€åœ¨æ”¶åˆ°å·¥å…·æ‰§è¡Œç»“æœåï¼š
         - å°†ç»“æœè½¬åŒ–ä¸ºè‡ªç„¶ã€å‹å¥½çš„ä¸­æ–‡å›åº”
         - çªå‡ºå…³é”®ä¿¡æ¯ï¼ˆå¦‚ç™»å½•çŠ¶æ€ã€æ“ä½œç»“æœç­‰ï¼‰
         - å¦‚æœæ“ä½œæˆåŠŸï¼Œç»™å‡ºç§¯æåé¦ˆ
         - å¦‚æœæ“ä½œå¤±è´¥ï¼Œè¯´æ˜å¯èƒ½çš„åŸå› 

        æ­£ç¡®ç¤ºä¾‹ï¼š
        ç”¨æˆ·ï¼šç™»å½•è´¦å·wyxï¼Œå¯†ç 124
        å“åº”ï¼š{{"tool":"login","arguments":{{"account":"wyx","password":"124"}}}}

        ç”¨æˆ·ï¼šç‚¹å‡»æµ‹è¯•æŒ‰é’®
        å“åº”ï¼š{{"tool":"test_button","arguments":{{"random_string":"test"}}}}

        é”™è¯¯ç¤ºä¾‹ï¼š
        ç”¨æˆ·ï¼šç™»å½•
        é”™è¯¯å“åº”ï¼š```json{{"tool":"login",...}}``` â†’ å«Markdown
        '''
        
        # å¯åŠ¨èŠå¤©ä¼šè¯
        await chat_session.start(system_message)

    except Exception as e:
        logger.error(f"Main function error: {e}")
        print(f"å¯åŠ¨å¤±è´¥: {e}")
    finally:
        # ç¡®ä¿èµ„æºè¢«æ¸…ç†
        await chat_session.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
